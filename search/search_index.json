{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"Decoy <p>Opinionated mocking library for Python</p> <p> </p> <p> Usage guide and documentation </p> <p>Decoy is a mocking library designed for effective and productive test-driven development in Python. If you want to use tests to guide the structure of your code, Decoy might be for you!</p> <p>Decoy mocks are async/await and type-checking friendly. Decoy is heavily inspired by (and/or stolen from) the excellent testdouble.js and Mockito projects. The Decoy API is powerful, easy to read, and strives to help you make good decisions about your code.</p>"},{"location":"#install","title":"Install","text":"<pre><code># pip\npip install decoy\n\n# poetry\npoetry add --dev decoy\n\n# pipenv\npipenv install --dev decoy\n</code></pre>"},{"location":"#setup","title":"Setup","text":""},{"location":"#pytest-setup","title":"Pytest setup","text":"<p>Decoy ships with its own pytest plugin, so once Decoy is installed, you're ready to start using it via its pytest fixture, called <code>decoy</code>.</p> <pre><code># test_my_thing.py\nfrom decoy import Decoy\n\ndef test_my_thing_works(decoy: Decoy) -&gt; None:\n    ...\n</code></pre>"},{"location":"#mypy-setup","title":"Mypy setup","text":"<p>By default, Decoy is compatible with Python typing and type-checkers like mypy. However, stubbing functions that return <code>None</code> can trigger a type checking error during correct usage of the Decoy API. To suppress these errors, add Decoy's plugin to your mypy configuration.</p> <pre><code># mypy.ini\nplugins = decoy.mypy\n</code></pre>"},{"location":"#other-testing-libraries","title":"Other testing libraries","text":"<p>Decoy works well with pytest, but if you use another testing library or framework, you can still use Decoy! You just need to do two things:</p> <ol> <li>Create a new instance of <code>Decoy()</code> before each test</li> <li>Call <code>decoy.reset()</code> after each test</li> </ol> <p>For example, using the built-in unittest framework, you would use the <code>setUp</code> fixture method to do <code>self.decoy = Decoy()</code> and the <code>tearDown</code> method to call <code>self.decoy.reset()</code>. For a working example, see <code>tests/test_unittest.py</code>.</p>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>This basic example assumes you are using pytest. For more detailed documentation, see Decoy's usage guide and API reference.</p> <p>Decoy will add a <code>decoy</code> fixture to pytest that provides its mock creation API.</p> <pre><code>from decoy import Decoy\n\ndef test_something(decoy: Decoy) -&gt; None:\n    ...\n</code></pre> <p>Note</p> <p>Importing the <code>Decoy</code> interface for type annotations is recommended, but optional. If your project does not use type annotations, you can simply write:</p> <pre><code>def test_something(decoy):\n    ...\n</code></pre>"},{"location":"#create-a-mock","title":"Create a mock","text":"<p>Use <code>decoy.mock</code> to create a mock based on some specification. From there, inject the mock into your test subject.</p> <pre><code>def test_add_todo(decoy: Decoy) -&gt; None:\n    todo_store = decoy.mock(cls=TodoStore)\n    subject = TodoAPI(store=todo_store)\n    ...\n</code></pre> <p>See creating mocks for more details.</p>"},{"location":"#stub-a-behavior","title":"Stub a behavior","text":"<p>Use <code>decoy.when</code> to configure your mock's behaviors. For example, you can set the mock to return a certain value when called in a certain way using <code>then_return</code>:</p> <pre><code>def test_add_todo(decoy: Decoy) -&gt; None:\n    \"\"\"Adding a todo should create a TodoItem in the TodoStore.\"\"\"\n    todo_store = decoy.mock(cls=TodoStore)\n    subject = TodoAPI(store=todo_store)\n\n    decoy.when(\n        todo_store.add(name=\"Write a test for adding a todo\")\n    ).then_return(\n        TodoItem(id=\"abc123\", name=\"Write a test for adding a todo\")\n    )\n\n    result = subject.add(\"Write a test for adding a todo\")\n    assert result == TodoItem(id=\"abc123\", name=\"Write a test for adding a todo\")\n</code></pre> <p>See stubbing with when for more details.</p>"},{"location":"#verify-a-call","title":"Verify a call","text":"<p>Use <code>decoy.verify</code> to assert that a mock was called in a certain way. This is best used with dependencies that are being used for their side-effects and don't return a useful value.</p> <pre><code>def test_remove_todo(decoy: Decoy) -&gt; None:\n    \"\"\"Removing a todo should remove the item from the TodoStore.\"\"\"\n    todo_store = decoy.mock(cls=TodoStore)\n    subject = TodoAPI(store=todo_store)\n\n    subject.remove(\"abc123\")\n\n    decoy.verify(todo_store.remove(id=\"abc123\"), times=1)\n</code></pre> <p>See spying with verify for more details.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#decoy.Decoy","title":"<code>decoy.Decoy</code>","text":"<p>Decoy mock factory and state container.</p> <p>You should create a new Decoy instance before each test and call <code>reset</code> after each test. If you use the <code>decoy</code> pytest fixture, this is done automatically. See the setup guide for more details.</p> <p>Example</p> <pre><code>decoy = Decoy()\n\n# test your subject\n...\n\ndecoy.reset()\n</code></pre>"},{"location":"api/#decoy.Decoy.mock","title":"<code>decoy.Decoy.mock(*, cls=None, func=None, name=None, is_async=False)</code>","text":"<p>Create a mock. See the mock creation guide for more details.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Optional[Any]</code> <p>A class definition that the mock should imitate.</p> <code>None</code> <code>func</code> <code>Optional[Any]</code> <p>A function definition the mock should imitate.</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>A name to use for the mock. If you do not use <code>cls</code> or <code>func</code>, you should add a <code>name</code>.</p> <code>None</code> <code>is_async</code> <code>bool</code> <p>Force the returned spy to be asynchronous. This argument only applies if you don't use <code>cls</code> nor <code>func</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>A spy typecast as the object it's imitating, if any.</p> <p>Example</p> <pre><code>def test_get_something(decoy: Decoy):\n    db = decoy.mock(cls=Database)\n    # ...\n</code></pre>"},{"location":"api/#decoy.Decoy.prop","title":"<code>decoy.Decoy.prop(_rehearsal_result)</code>","text":"<p>Create property setter and deleter rehearsals.</p> <p>See property mocking guide for more details.</p> <p>Parameters:</p> Name Type Description Default <code>_rehearsal_result</code> <code>ReturnT</code> <p>The property to mock, for typechecking.</p> required <p>Returns:</p> Type Description <code>Prop[ReturnT]</code> <p>A prop rehearser on which you can call <code>set</code> or</p> <code>Prop[ReturnT]</code> <p><code>delete</code> to create property rehearsals.</p>"},{"location":"api/#decoy.Decoy.reset","title":"<code>decoy.Decoy.reset()</code>","text":"<p>Reset all mock state.</p> <p>This method should be called after every test to ensure spies and stubs don't leak between tests. The <code>decoy</code> fixture provided by the pytest plugin will call <code>reset</code> automatically.</p> <p>The <code>reset</code> method may also trigger warnings if Decoy detects any questionable mock usage. See decoy.warnings for more details.</p>"},{"location":"api/#decoy.Decoy.verify","title":"<code>decoy.Decoy.verify(*_rehearsal_results, times=None, ignore_extra_args=False)</code>","text":"<p>Verify a mock was called using one or more rehearsals.</p> <p>See verification usage guide for more details.</p> <p>Parameters:</p> Name Type Description Default <code>_rehearsal_results</code> <code>Any</code> <p>The return value of rehearsals, unused except to determine how many rehearsals to verify.</p> <code>()</code> <code>times</code> <code>Optional[int]</code> <p>How many times the call should appear. If <code>times</code> is specified, the call count must match exactly, otherwise the call must appear at least once. The <code>times</code> argument must be used with exactly one rehearsal.</p> <code>None</code> <code>ignore_extra_args</code> <code>bool</code> <p>Allow the rehearsal to specify fewer arguments than the actual call. Decoy will compare and match any given arguments, ignoring unspecified arguments.</p> <code>False</code> <p>Raises:</p> Type Description <code>VerifyError</code> <p>The verification was not satisfied.</p> <p>Example</p> <pre><code>def test_create_something(decoy: Decoy):\n    gen_id = decoy.mock(func=generate_unique_id)\n\n    # ...\n\n    decoy.verify(gen_id(\"model-prefix_\"))\n</code></pre> <p>Note</p> <p>A \"rehearsal\" is an actual call to the test fake. The fact that the call is written inside <code>verify</code> is purely for typechecking and API sugar. Decoy will pop the last call(s) to any fake off its call stack, which will end up being the call inside <code>verify</code>.</p>"},{"location":"api/#decoy.Decoy.when","title":"<code>decoy.Decoy.when(_rehearsal_result, *, ignore_extra_args=False)</code>","text":"<p>Create a <code>Stub</code> configuration using a rehearsal call.</p> <p>See stubbing usage guide for more details.</p> <p>Parameters:</p> Name Type Description Default <code>_rehearsal_result</code> <code>ReturnT</code> <p>The return value of a rehearsal, used for typechecking.</p> required <code>ignore_extra_args</code> <code>bool</code> <p>Allow the rehearsal to specify fewer arguments than the actual call. Decoy will compare and match any given arguments, ignoring unspecified arguments.</p> <code>False</code> <p>Returns:</p> Type Description <code>Stub[ReturnT]</code> <p>A stub to configure using <code>then_return</code>,</p> <code>Stub[ReturnT]</code> <p><code>then_raise</code>, <code>then_do</code>,</p> <code>Stub[ReturnT]</code> <p>or <code>then_enter_with</code>.</p> <p>Example</p> <pre><code>db = decoy.mock(cls=Database)\ndecoy.when(db.exists(\"some-id\")).then_return(True)\n</code></pre> <p>Note</p> <p>The \"rehearsal\" is an actual call to the test fake. Because the call is written inside <code>when</code>, Decoy is able to infer that the call is a rehearsal for stub configuration purposes rather than a call from the code-under-test.</p>"},{"location":"api/#decoy.Stub","title":"<code>decoy.Stub</code>","text":"<p>             Bases: <code>Generic[ReturnT]</code></p> <p>A rehearsed Stub that can be used to configure mock behaviors.</p> <p>See stubbing usage guide for more details.</p>"},{"location":"api/#decoy.Stub.then_do","title":"<code>decoy.Stub.then_do(action)</code>","text":"<p>Configure the stub to trigger an action.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>Callable[..., Union[ReturnT, Coroutine[Any, Any, ReturnT]]]</code> <p>The function to call. Called with whatever arguments are actually passed to the stub. May be an <code>async def</code> function if the mock is also asynchronous.</p> required <p>Raises:</p> Type Description <code>MockNotAsyncError</code> <p><code>action</code> was an <code>async def</code> function, but the mock is synchronous.</p>"},{"location":"api/#decoy.Stub.then_enter_with","title":"<code>decoy.Stub.then_enter_with(value)</code>","text":"<p>Configure the stub to return a value wrapped in a context manager.</p> <p>The wrapping context manager is compatible with both the synchronous and asynchronous context manager interfaces.</p> <p>See the context manager usage guide for more details.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>ContextValueT</code> <p>A return value to wrap in a ContextManager.</p> required"},{"location":"api/#decoy.Stub.then_raise","title":"<code>decoy.Stub.then_raise(error)</code>","text":"<p>Configure the stub to raise an error.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Exception</code> <p>The error to raise.</p> required <p>Note</p> <p>Setting a stub to raise will prevent you from writing new rehearsals, because they will raise. If you need to make more calls to <code>when</code>, you'll need to wrap your rehearsal in a <code>try</code>.</p>"},{"location":"api/#decoy.Stub.then_return","title":"<code>decoy.Stub.then_return(*values)</code>","text":"<p>Configure the stub to return value(s).</p> <p>Parameters:</p> Name Type Description Default <code>*values</code> <code>ReturnT</code> <p>Zero or more return values. Multiple values will result      in different return values for subsequent calls, with the      last value latching in once all other values have returned.</p> <code>()</code>"},{"location":"api/#decoy.Prop","title":"<code>decoy.Prop</code>","text":"<p>             Bases: <code>Generic[ReturnT]</code></p> <p>Rehearsal creator for mocking property setters and deleters.</p> <p>See property mocking guide for more details.</p>"},{"location":"api/#decoy.Prop.delete","title":"<code>decoy.Prop.delete()</code>","text":"<p>Create a property deleter rehearsal.</p> <p>By wrapping <code>delete</code> in a call to <code>when</code> or <code>verify</code>, you can stub or verify a call to a property deleter.</p> <p>Example</p> <pre><code>some_obj = decoy.mock()\ndel some_obj.prop\ndecoy.verify(decoy.prop(some_obj.prop).delete())\n</code></pre>"},{"location":"api/#decoy.Prop.set","title":"<code>decoy.Prop.set(value)</code>","text":"<p>Create a property setter rehearsal.</p> <p>By wrapping <code>set</code> in a call to <code>when</code> or <code>verify</code>, you can stub or verify a call to a property setter.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>ReturnT</code> <p>The value</p> required <p>Example</p> <pre><code>some_obj = decoy.mock()\nsome_obj.prop = 42\ndecoy.verify(decoy.prop(some_obj.prop).set(42))\n</code></pre>"},{"location":"api/#decoy.matchers","title":"<code>decoy.matchers</code>","text":"<p>Matcher helpers.</p> <p>A \"matcher\" is a class with an <code>__eq__</code> method defined. Use them anywhere in your test where you would use an actual value for equality (<code>==</code>) comparison.</p> <p>Matchers help you loosen assertions where strict adherence to an exact value is not relevant to what you're trying to test. See the matchers guide for more details.</p> <p>Example</p> <pre><code>from decoy import Decoy, matchers\n\n# ...\n\ndef test_logger_called(decoy: Decoy):\n    # ...\n    decoy.verify(\n        logger.log(msg=matchers.StringMatching(\"hello\"))\n    )\n</code></pre> <p>Note</p> <p>Identity comparisons (<code>is</code>) will not work with matchers. Decoy only uses equality comparisons (<code>==</code>) for stubbing and verification.</p>"},{"location":"api/#decoy.matchers.Anything","title":"<code>decoy.matchers.Anything()</code>","text":"<p>Match anything except None.</p> <p>Example</p> <pre><code>assert \"foobar\" == Anything()\nassert None != Anything()\n</code></pre>"},{"location":"api/#decoy.matchers.AnythingOrNone","title":"<code>decoy.matchers.AnythingOrNone()</code>","text":"<p>Match anything including None.</p> <p>Example</p> <pre><code>assert \"foobar\" == AnythingOrNone()\nassert None == AnythingOrNone()\n</code></pre>"},{"location":"api/#decoy.matchers.Captor","title":"<code>decoy.matchers.Captor()</code>","text":"<p>Match anything, capturing its value.</p> <p>The last captured value will be set to <code>captor.value</code>. All captured values will be placed in the <code>captor.values</code> list, which can be helpful if a captor needs to be triggered multiple times.</p> <p>Example</p> <pre><code>captor = Captor()\nassert \"foobar\" == captor\nprint(captor.value)  # \"foobar\"\nprint(captor.values)  # [\"foobar\"]\n</code></pre>"},{"location":"api/#decoy.matchers.DictMatching","title":"<code>decoy.matchers.DictMatching(values)</code>","text":"<p>Match any dictionary with the passed in keys / values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Mapping[str, Any]</code> <p>Keys and values to check.</p> required <p>Example</p> <pre><code>value = {\"hello\": \"world\", \"goodbye\": \"so long\"}\nassert value == matchers.DictMatching({\"hello\": \"world\"})\n</code></pre>"},{"location":"api/#decoy.matchers.ErrorMatching","title":"<code>decoy.matchers.ErrorMatching(error, match=None)</code>","text":"<p>Match any error matching an Exception type and optional message matcher.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Type[ErrorT]</code> <p>Exception type to match against.</p> required <code>match</code> <code>Optional[str]</code> <p>Pattern to check against; will be compiled into an re.Pattern.</p> <code>None</code> <p>Example</p> <pre><code>assert ValueError(\"oh no!\") == ErrorMatching(ValueError)\nassert ValueError(\"oh no!\") == ErrorMatching(ValueError, match=\"no\")\n</code></pre>"},{"location":"api/#decoy.matchers.HasAttributes","title":"<code>decoy.matchers.HasAttributes(attributes)</code>","text":"<p>Match anything with the passed in attributes.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>Mapping[str, Any]</code> <p>Attribute values to check.</p> required <p>Example</p> <pre><code>@dataclass\nclass HelloWorld:\n    hello: str = \"world\"\n    goodby: str = \"so long\"\n\nassert HelloWorld() == matchers.HasAttributes({\"hello\": \"world\"})\n</code></pre>"},{"location":"api/#decoy.matchers.IsA","title":"<code>decoy.matchers.IsA(match_type, attributes=None)</code>","text":"<p>Match anything that satisfies the passed in type.</p> <p>Parameters:</p> Name Type Description Default <code>match_type</code> <code>type</code> <p>Type to match.</p> required <code>attributes</code> <code>Optional[Mapping[str, Any]]</code> <p>Optional set of attributes to match</p> <code>None</code> <p>Example</p> <pre><code>assert \"foobar\" == IsA(str)\nassert datetime.now() == IsA(datetime)\nassert 42 == IsA(int)\n\n@dataclass\nclass HelloWorld:\n    hello: str = \"world\"\n    goodby: str = \"so long\"\n\nassert HelloWorld() == IsA(HelloWorld, {\"hello\": \"world\"})\n</code></pre>"},{"location":"api/#decoy.matchers.IsNot","title":"<code>decoy.matchers.IsNot(value)</code>","text":"<p>Match anything that isn't the passed in value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>object</code> <p>Value to check against.</p> required <p>Example</p> <pre><code>assert \"foobar\" == IsNot(\"bazquux\")\nassert 42 == IsNot(\"the question\")\nassert 1 != IsNot(1)\n</code></pre>"},{"location":"api/#decoy.matchers.ListMatching","title":"<code>decoy.matchers.ListMatching(values)</code>","text":"<p>Match any list with the passed in values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>List[Any]</code> <p>Values to check.</p> required <p>Example</p> <pre><code>value = [1, 2, 3]\nassert value == matchers.ListMatching([1, 2])\n</code></pre>"},{"location":"api/#decoy.matchers.StringMatching","title":"<code>decoy.matchers.StringMatching(match)</code>","text":"<p>Match any string matching the passed in pattern.</p> <p>Parameters:</p> Name Type Description Default <code>match</code> <code>str</code> <p>Pattern to check against; will be compiled into an re.Pattern.</p> required <p>Example</p> <pre><code>assert \"foobar\" == StringMatching(\"bar\")\nassert \"foobar\" != StringMatching(\"^bar\")\n</code></pre>"},{"location":"api/#decoy.errors","title":"<code>decoy.errors</code>","text":"<p>Errors raised by Decoy.</p> <p>See the errors guide for more details.</p>"},{"location":"api/#decoy.errors.MissingRehearsalError","title":"<code>decoy.errors.MissingRehearsalError</code>","text":"<p>             Bases: <code>ValueError</code></p> <p>An error raised when a Decoy method is called without rehearsal(s).</p> <p>This error is raised if you use <code>when</code>, <code>verify</code>, or <code>prop</code> incorrectly in your tests. When using async/await, this error can be triggered if you forget to include <code>await</code> with your rehearsal.</p> <p>See the MissingRehearsalError guide for more details.</p>"},{"location":"api/#decoy.errors.MockNameRequiredError","title":"<code>decoy.errors.MockNameRequiredError</code>","text":"<p>             Bases: <code>ValueError</code></p> <p>An error raised if a name is not provided for a mock.</p> <p>See the MockNameRequiredError guide for more details.</p>"},{"location":"api/#decoy.errors.MockNotAsyncError","title":"<code>decoy.errors.MockNotAsyncError</code>","text":"<p>             Bases: <code>TypeError</code></p> <p>An error raised when an asynchronous function is used with a synchronous mock.</p> <p>This error is raised if you pass an <code>async def</code> function to a synchronous stub's <code>then_do</code> method. See the MockNotAsyncError guide for more details.</p>"},{"location":"api/#decoy.errors.VerifyError","title":"<code>decoy.errors.VerifyError</code>","text":"<p>             Bases: <code>AssertionError</code></p> <p>An error raised when actual calls do not match rehearsals given to <code>verify</code>.</p> <p>See spying with verify for more details.</p> <p>Attributes:</p> Name Type Description <code>rehearsals</code> <code>Sequence[VerifyRehearsal]</code> <p>Rehearsals that were being verified.</p> <code>calls</code> <code>Sequence[SpyEvent]</code> <p>Actual calls to the mock(s).</p> <code>times</code> <code>Optional[int]</code> <p>The expected number of calls to the mock, if any.</p>"},{"location":"api/#decoy.warnings","title":"<code>decoy.warnings</code>","text":"<p>Warnings raised by Decoy.</p> <p>See the warnings guide for more details.</p>"},{"location":"api/#decoy.warnings.DecoyWarning","title":"<code>decoy.warnings.DecoyWarning</code>","text":"<p>             Bases: <code>UserWarning</code></p> <p>Base class for Decoy warnings.</p>"},{"location":"api/#decoy.warnings.IncorrectCallWarning","title":"<code>decoy.warnings.IncorrectCallWarning</code>","text":"<p>             Bases: <code>DecoyWarning</code></p> <p>A warning raised if a Decoy mock with a spec is called incorrectly.</p> <p>If a call to a Decoy mock is incorrect according to <code>inspect.signature</code>, this warning will be raised. See the IncorrectCallWarning guide for more details.</p>"},{"location":"api/#decoy.warnings.MiscalledStubWarning","title":"<code>decoy.warnings.MiscalledStubWarning</code>","text":"<p>             Bases: <code>DecoyWarning</code></p> <p>A warning when a configured Stub is called with non-matching arguments.</p> <p>This warning is raised if a mock is both:</p> <ul> <li>Configured as a stub with <code>when</code></li> <li>Called with arguments that do not match any configured behaviors</li> </ul> <p>See the MiscalledStubWarning guide for more details.</p> <p>Attributes:</p> Name Type Description <code>rehearsals</code> <code>Sequence[SpyRehearsal]</code> <p>The mocks's configured rehearsals.</p> <code>calls</code> <code>Sequence[SpyEvent]</code> <p>Actual calls to the mock.</p>"},{"location":"api/#decoy.warnings.RedundantVerifyWarning","title":"<code>decoy.warnings.RedundantVerifyWarning</code>","text":"<p>             Bases: <code>DecoyWarning</code></p> <p>A warning when a mock is redundantly checked with <code>verify</code>.</p> <p>A <code>verify</code> assertion is redundant if:</p> <ul> <li>A given call is used as a <code>when</code> rehearsal</li> <li>That same call is later used in a <code>verify</code> check</li> </ul> <p>See the RedundantVerifyWarning guide for more details.</p>"},{"location":"api/#decoy.pytest_plugin","title":"<code>decoy.pytest_plugin</code>","text":"<p>Pytest plugin to setup and teardown a Decoy instance.</p> <p>The plugin will be registered with pytest when you install Decoy. It adds a fixture without modifying any other pytest behavior. Its usage is optional but highly recommended.</p>"},{"location":"api/#decoy.pytest_plugin.decoy","title":"<code>decoy.pytest_plugin.decoy()</code>","text":"<p>Get a decoy.Decoy container and reset it after the test.</p> <p>This function is function-scoped pytest fixture that will be automatically inserted by the plugin.</p> <p>Example</p> <pre><code>def test_my_thing(decoy: Decoy) -&gt; None:\n    my_fake_func = decoy.mock()\n    # ...\n</code></pre>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>All contributions are greatly appreciated! Before contributing, please read the code of conduct.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>This project uses Poetry to manage dependencies and builds, and you will need to install it before working on Decoy.</p> <p>Once Poetry is installed, you should be good to set up a virtual environment and install development dependencies. Python 3.11 is recommended for development.</p> <pre><code>git clone https://github.com/mcous/decoy.git\ncd decoy\npoetry install\n</code></pre>"},{"location":"contributing/#development-tasks","title":"Development Tasks","text":"<p>Decoy uses poethepoet to manage development tasks. If you want to quickly check everything, run the following:</p> <pre><code>poetry run poe all\n</code></pre>"},{"location":"contributing/#tests","title":"Tests","text":"<p>Decoy's tests are run using pytest. To run tests in watch mode:</p> <pre><code>poetry run poe test\n</code></pre> <p>To run tests once and report coverage</p> <pre><code>poetry run poe test-once\npoetry run poe coverage\n</code></pre> <p>In an exciting twist, since version 1.6.0, Decoy's tests rely on Decoy itself to test (and more importantly, design) the relationships between Decoy's internal APIs. This means:</p> <ul> <li>Decoy's unit test suite serves as an end-to-end test of Decoy by virtue of existing (wow, very meta, actually kind of cool).</li> <li>Changes that break a small part of Decoy may result in a large number of test failures, because if Decoy breaks it can't be used to test itself.</li> </ul> <p>If you find yourself in a situation where Decoy's test suite has blown up, concentrate on getting the test suites that don't use Decoy to pass. From there, lean on the type-checker to guide you to any components that aren't properly hooked up. Decoy also has a end-to-end smoke test suite (<code>tests/test_decoy.py</code>) that can be helpful in getting things back to green.</p>"},{"location":"contributing/#checks","title":"Checks","text":"<p>Decoy's source code is typechecked with mypy and linted/formatted with ruff.</p> <pre><code>poetry run poe check\npoetry run poe lint\npoetry run poe format\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Decoy's documentation is built with mkdocs, which you can use to preview the documentation site locally.</p> <pre><code>poetry run docs\n</code></pre>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>The library and documentation will be deployed to PyPI and GitHub Pages, respectively, by CI. To trigger the deploy, cut a new version and push it to GitHub.</p> <p>Decoy adheres to semantic versioning, so care should be taken to bump accurately.</p> <pre><code># checkout the main branch and pull down latest changes\ngit checkout main\ngit pull\n\n# bump the version\n# replace ${bump_version} with a bump specifier, like \"minor\"\npoetry version ${bump_version}\n\n# add the bumped pyproject.toml\ngit add pyproject.toml\n\n# commit and tag the bump\n# replace ${release_version} with the actual version string\ngit commit -m \"chore(release): ${release_version}\"\ngit tag -a v${release_version} -m \"chore(release): ${release_version}\"\ngit push --follow-tags\n</code></pre>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2020-2023, Michael Cousins</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"advanced/context-managers/","title":"Mocking context managers","text":"<p>In Python, <code>with</code> statement context managers provide an extremely useful interface to execute code inside a given \"runtime context.\" This context can define consistent, failsafe setup and teardown behavior. For example, Python's built-in file objects provide a context manager interface to ensure the underlying file resource is opened and closed cleanly, without the caller having to explicitly deal with it:</p> <pre><code>with open(\"hello-world.txt\", \"r\") as f:\n    contents = f.read()\n</code></pre> <p>You can use Decoy to mock out your dependencies that should provide a context manager interface.</p>"},{"location":"advanced/context-managers/#generator-based-context-managers","title":"Generator-based context managers","text":"<p>Using the contextlib module, you can decorate a generator function or method to turn its yielded value into a context manager. This is a great API, and one that Decoy is well-suited to mock. To mock a generator function context manager, use decoy.Stub.then_enter_with.</p> <pre><code>import contextlib\nfrom my_module.core import Core\nfrom my_module.config import Config, ConfigLoader\n\ndef test_loads_config(decoy: Decoy) -&gt; None:\n    \"\"\"It should load config from a ConfigLoader dependency.\n\n    In this example, we know we're going to read/write config\n    to/from an external source, like the filesystem. So we want to\n    implement this dependency as a context manager to ensure\n    resource cleanup.\n    \"\"\"\n    config_loader = decoy.mock(ConfigLoader)\n    config = decoy.mock(Config)\n\n    subject = Core(config_loader=config_loader)\n\n    decoy.when(config_loader.load()).then_enter_with(config)\n    decoy.when(config.read(\"some_flag\")).then_return(True)\n\n    result = subject.get_config(\"some_flag\")\n\n    assert result is True\n</code></pre> <p>From this test, we could sketch out the following dependency APIs...</p> <pre><code># config.py\nimport contextlib\nfrom typing import Generator\n\nclass Config:\n    def read(self, name: str) -&gt; bool:\n        ...\n\nclass ConfigLoader:\n    @contextlib.contextmanager\n    def load(self) -&gt; Generator[Config, None, None]:\n        ...\n</code></pre> <p>...along with our test subject's implementation to pass the test...</p> <pre><code># core.py\nfrom .config import Config, ConfigLoader\n\nclass Core:\n    def __init__(self, config_loader: ConfigLoader) -&gt; None:\n        self._config_loader = config_loader\n\n    def get_config(self, name: str) -&gt; bool:\n        with self._config_loader.load() as config:\n            return config.read(name)\n</code></pre>"},{"location":"advanced/context-managers/#general-context-managers","title":"General context managers","text":"<p>A context manager is simply an object with both <code>__enter__</code> and <code>__exit__</code> methods defined. Decoy mocks have both these methods defined, so they are compatible with the <code>with</code> statement. In the author's opinion, tests that mock <code>__enter__</code> and <code>__exit__</code> (or any double-underscore method) are harder to read and understand than tests that do not, so generator-based context managers should be preferred where applicable.</p> <p>Using our earlier example, maybe you'd prefer to use a single <code>Config</code> dependency to both load the configuration resource and read values.</p> <pre><code>import contextlib\nfrom my_module.core import Core\nfrom my_module.config import Config, ConfigLoader\n\ndef test_loads_config(decoy: Decoy) -&gt; None:\n    \"\"\"It should load config from a Config dependency.\"\"\"\n    config = decoy.mock(Config)\n    subject = Core(config=config)\n\n    def _handle_enter() -&gt; Config:\n        \"\"\"Ensure `read` only works if context is entered.\"\"\"\n        decoy.when(config.read(\"some_flag\")).then_return(True)\n        return config\n\n    def _handle_exit() -&gt; None:\n        \"\"\"Ensure test fails if subject calls `read` after exit.\"\"\"\n        decoy.when(\n            config.read(\"some_flag\")\n        ).then_raise(AssertionError(\"Context manager was exited\"))\n\n    decoy.when(config.__enter__()).then_do(_handle_enter)\n    decoy.when(config.__exit__(None, None, None)).then_do(_handle_exit)\n\n    result = subject.get_config(\"some_flag\")\n\n    assert result is True\n</code></pre> <p>From this test, our dependency APIs would be...</p> <pre><code># config.py\nfrom __future__ import annotations\nfrom types import TracebackType\nfrom typing import Type, Optional\n\nclass Config:\n    def __enter__(self) -&gt; Config:\n        ...\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; Optional[bool]:\n        ...\n\n    def read(self, name: str) -&gt; bool:\n        ...\n</code></pre> <p>...along with our test subject's implementation to pass the test...</p> <pre><code># core.py\nfrom .config import Config\n\nclass Core:\n    def __init__(self, config: Config) -&gt; None:\n        self._config = config\n\n    def get_config(self, name: str) -&gt; bool:\n        with self._config as loaded_config:\n            return loaded_config.read(name)\n</code></pre>"},{"location":"advanced/context-managers/#asynchronous-context-managers","title":"Asynchronous context managers","text":"<p>Decoy is also compatible with mocking the async <code>__aenter__</code> and <code>__aexit__</code> methods of async context managers.</p> <pre><code>import pytest\nimport contextlib\nfrom my_module.core import Core\nfrom my_module.config import Config, ConfigLoader\n\nasync def test_loads_config(decoy: Decoy) -&gt; None:\n    \"\"\"It should load config from a Config dependency.\"\"\"\n    config = decoy.mock(Config)\n    subject = Core(config=config)\n\n    async def _handle_enter() -&gt; Config:\n        \"\"\"Ensure `read` only works if context is entered.\"\"\"\n        decoy.when(config.read(\"some_flag\")).then_return(True)\n        return config\n\n    async def _handle_exit() -&gt; None:\n        \"\"\"Ensure test fails if subject calls `read` after exit.\"\"\"\n        decoy.when(\n            config.read(\"some_flag\")\n        ).then_raise(AssertionError(\"Context manager was exited\"))\n\n    decoy.when(await config.__aenter__()).then_do(_handle_enter)\n    decoy.when(await config.__aexit__()).then_do(_handle_exit)\n\n    result = await subject.get_config(\"some_flag\")\n\n    assert result is True\n</code></pre> <p>This test spits out the following APIs and implementations...</p> <pre><code># config.py\nfrom __future__ import annotations\nfrom types import TracebackType\nfrom typing import Type, Optional\n\nclass Config:\n    async def __aenter__(self) -&gt; Config:\n        ...\n\n    async def __aexit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; Optional[bool]:\n        ...\n\n    def read(self, name: str) -&gt; bool:\n        ...\n</code></pre> <p>...along with our test subject's implementation to pass the test...</p> <pre><code># core.py\nfrom .config import Config\n\nclass Core:\n    def __init__(self, config: Config) -&gt; None:\n        self._config = config\n\n    async def get_config(self, name: str) -&gt; bool:\n        async with self._config as loaded_config:\n            return loaded_config.read(name)\n</code></pre>"},{"location":"advanced/properties/","title":"Mocking property attributes","text":"<p>Python property attributes provide an interface for creating read-only properties and properties with getters, setters, and deleters. You can use Decoy to stub properties and verify calls to property setters and deleters.</p>"},{"location":"advanced/properties/#default-behavior","title":"Default behavior","text":"<p>Unlike mock method calls - which have a default return value of <code>None</code> - Decoy's default return value for attribute access is another mock. So you don't need to configure anything explicitly if you need a <code>@property</code> getter to return another mock; Decoy will do this for you.</p> <pre><code>class SubDep:\n    ...\n\nclass Dep:\n    @property\n    def sub(self) -&gt; SubDep:\n        ...\n\ndef test(decoy: Decoy) -&gt; None:\n    dep = decoy.mock(cls=Dep)  # &lt;- mock of class Dep\n    sub = dep.sub              # &lt;- mock of class SubDep\n    ...\n</code></pre>"},{"location":"advanced/properties/#stubbing-property-access","title":"Stubbing property access","text":""},{"location":"advanced/properties/#stubbing-a-getter","title":"Stubbing a getter","text":"<p>If you would like to stub a return value for a property that is different than the default behavior, simply use the property itself as your rehearsal.</p> <pre><code>dependency = decoy.mock(name=\"dependency\")\n\ndecoy.when(\n    dependency.some_property  # &lt;- \"rehearsal\" of a property getter\n).then_return(42)\n\nassert dep.some_property == 42\n</code></pre> <p>You can also configure any other behavior, like raising an error.</p> <pre><code>dependency = decoy.mock(name=\"dependency\")\n\ndecoy.when(\n    dependency.some_property\n).then_raise(RuntimeError(\"oh no\"))\n\nwith pytest.raises(RuntimeError, match=\"oh no\"):\n    dependency.some_property\n</code></pre>"},{"location":"advanced/properties/#stubbing-a-setter-or-deleter","title":"Stubbing a setter or deleter","text":"<p>While you cannot stub a return value for a getter or setter, you can stub a <code>raise</code> or a side effect by combining decoy.Decoy.when with decoy.Decoy.prop.</p> <p>The <code>prop</code> method allows you to create rehearsals of setters and deleters. Use decoy.Prop.set to create a setter rehearsal, and decoy.Prop.delete to create a deleter rehearsal.</p> <pre><code>dependency = decoy.mock(name=\"dependency\")\n\ndecoy.when(\n    decoy.prop(dependency.some_property).set(42)\n).then_raise(RuntimeError(\"oh no\"))\n\ndecoy.when(\n    decoy.prop(dependency.some_property).delete()\n).then_raise(RuntimeError(\"what a disaster\"))\n\nwith pytest.raises(RuntimeError, match=\"oh no\"):\n    dependency.some_property = 42\n\nwith pytest.raises(RuntimeError, match=\"what a disaster\"):\n    del dependency.some_property\n</code></pre> <p>Tip</p> <p>You cannot use decoy.Stub.then_return with property setters and deleters, because set and delete expressions do not return a value in Python.</p>"},{"location":"advanced/properties/#verifying-property-access","title":"Verifying property access","text":"<p>You can verify calls to property setters and deleters by combining decoy.Decoy.verify with decoy.Decoy.prop, the same way you would configure a stub.</p> <p>Use this feature sparingly! If you're designing a dependency that triggers a side-effect, consider using a regular method rather than a property setter/deleter. It'll probably make your code easier to read and reason with.</p> <p>Mocking and verifying property setters and deleters is most useful for testing code that needs to interact with older or legacy dependencies that would be prohibitively expensive to redesign.</p> <p>Tip</p> <p>You cannot <code>verify</code> getters. The <code>verify</code> method is for verifying side-effects, and it is the opinion of the author that property getters should not trigger side-effects. Getter-triggered side effects are confusing and do not communicate the design intent of a system.</p>"},{"location":"advanced/properties/#verifying-a-setter","title":"Verifying a setter","text":"<p>Use decoy.Prop.set to create a setter rehearsal to use in decoy.Decoy.verify.</p> <pre><code>dependency = decoy.mock(name=\"dependency\")\n\ndependency.some_property = 42\n\ndecoy.verify(\n    decoy.prop(dependency.some_property).set(42)  # &lt;- \"rehearsal\" of a property setter\n)\n</code></pre>"},{"location":"advanced/properties/#verifying-a-deleter","title":"Verifying a deleter","text":"<p>Use decoy.Prop.delete to create a deleter rehearsal to use in decoy.Decoy.verify.</p> <pre><code>dependency = decoy.mock(name=\"dependency\")\n\ndel dependency.some_property\n\ndecoy.verify(\n    decoy.prop(dependency.some_property).delete()  # &lt;- \"rehearsal\" of a property deleter\n)\n</code></pre>"},{"location":"advanced/properties/#example","title":"Example","text":"<p>In this example, we're developing a <code>Core</code> unit, with a <code>Config</code> dependency. We want to test that we get, set, and delete the <code>port</code> property of the <code>Config</code> dependency when various methods of <code>Core</code> are used.</p> <pre><code>from decoy import Decoy\n\n\nclass InvalidPortValue(ValueError):\n    \"\"\"Exception raised when a given port value is invalid.\"\"\"\n\n\nclass Config:\n    \"\"\"Config dependency.\"\"\"\n\n    @property\n    def port(self) -&gt; int:\n        ...\n\n    @port.setter\n    def port(self) -&gt; None:\n        ...\n\n    @port.deleter\n    def port(self) -&gt; None:\n        ...\n\n\nclass Core:\n    \"\"\"Core test subject.\"\"\"\n\n    def __init__(self, config: Config) -&gt; None:\n        self._config = config\n\n    def get_port(self) -&gt; int:\n        return self._config.port\n\n    def set_port(self, port: int) -&gt; None:\n        try:\n            self._config.port = port\n        except ValueError as e:\n            raise InvalidPortValue(str(e)) from e\n\n    def reset_port(self) -&gt; None:\n        del self._config.port\n\n\ndef test_gets_port(decoy: Decoy) -&gt; None:\n    \"\"\"Core should get the port number from its Config dependency.\"\"\"\n    config = decoy.mock(cls=Config)\n    subject = Core(config=config)\n\n    decoy.when(\n        config.port  # &lt;- \"rehearsal\" of a property getter\n    ).then_return(42)\n\n    result = subject.get_port()\n\n    assert result == 42\n\n\ndef test_rejects_invalid_port(decoy: Decoy) -&gt; None:\n    \"\"\"Core should re-raise if the port number is set to an invalid value.\"\"\"\n    config = decoy.mock(cls=Config)\n    subject = Core(config=config)\n\n    decoy.when(\n        decoy.prop(config.port).set(9001)  # &lt;- \"rehearsal\" of a property setter\n    ).then_raise(ValueError(\"there's no way that can be right\"))\n\n    with pytest.raises(InvalidPortValue, \"there's no way\"):\n        subject.set_port(9001)\n\n\ndef test_sets_port(decoy: Decoy) -&gt; None:\n    \"\"\"Core should set the port number in its Config dependency.\"\"\"\n    config = decoy.mock(cls=Config)\n    subject = Core(config=config)\n\n    subject.set_port(101)\n\n    decoy.verify(\n        decoy.prop(config.port).set(101)  # &lt;- \"rehearsal\" of a property setter\n    )\n\ndef test_resets_port(decoy: Decoy) -&gt; None:\n    \"\"\"Core should delete the port number in its Config dependency.\"\"\"\n    config = decoy.mock(cls=Config)\n    subject = Core(config=config)\n\n    subject.reset_port()\n\n    decoy.verify(\n        decoy.prop(config.port).delete()  # &lt;- \"rehearsal\" of a property deleter\n    )\n</code></pre>"},{"location":"usage/create/","title":"Creating mocks","text":"<p>Decoy mocks are flexible objects that can be used in place of a class instance or a callable object, like a function. Mocks are created using the decoy.Decoy.mock method.</p>"},{"location":"usage/create/#default-behaviors","title":"Default behaviors","text":"<p>Decoy mock objects are flexible, callable proxy objects that simply record interactions made with the object. Accessing any property of the mock will return a child mock, and calling the mock itself or any \"method\" of the mock will return <code>None</code>.</p> <pre><code>my_mock = decoy.mock(name=\"my_mock\")\n\nassert my_mock() is None\nassert my_mock.some_method(\"hello world\") is None\nassert my_mock.some_property.some_method(\"hey\") is None\n</code></pre> <p>You can configure a mock's behaviors using decoy.when. You can make assertions about how a mock was called using decoy.verify.</p>"},{"location":"usage/create/#mocking-a-class","title":"Mocking a class","text":"<p>To mock a class instance, pass the <code>cls</code> argument to <code>decoy.mock</code>. Decoy will inspect type annotations and method signatures to set a name for use in assertion messages, configure methods as synchronous or asynchronous, and understand function keyword arguments.</p> <pre><code>some_dependency = decoy.mock(cls=SomeDependency)\n</code></pre> <p>To type checkers, the mock will appear to have the exact same type as the <code>cls</code> argument. The mock will also pass <code>isinstance</code> checks.</p>"},{"location":"usage/create/#mocking-a-function","title":"Mocking a function","text":"<p>To mock a function, pass the <code>func</code> argument to <code>decoy.mock</code>. Decoy will inspect <code>func</code> to set a name for use in assertion messages, configure the mock as synchronous or asynchronous, and understand function keyword arguments.</p> <pre><code>mock_function = decoy.mock(func=some_function)\n</code></pre> <p>To type checkers, the mock will appear to have the exact same type as the <code>func</code> argument. The function mock will pass <code>inspect.signature</code> checks.</p>"},{"location":"usage/create/#creating-a-mock-without-a-spec","title":"Creating a mock without a spec","text":"<p>You can call <code>decoy.mock</code> without using <code>cls</code> or <code>func</code>. A spec-less mock is useful for dependency interfaces like callback functions.</p> <p>When creating a mock without a spec, you must use the <code>name</code> argument to give the mock a name to use in assertion messages. You must use the <code>is_async</code> argument if the created mock will be used as an asynchronous callable.</p> <pre><code>callback = decoy.mock(name=\"callback\")\nasync_callback = decoy.mock(name=\"async_callback\", is_async=True)\n</code></pre>"},{"location":"usage/errors-and-warnings/","title":"Errors and warnings","text":"<p>Decoy's job as a mocking library is to provide you, the user, with useful design feedback about your code under test. Sometimes, this design feedback comes in the form of exceptions and warnings raised.</p>"},{"location":"usage/errors-and-warnings/#errors","title":"Errors","text":""},{"location":"usage/errors-and-warnings/#verifyerror","title":"VerifyError","text":"<p>A decoy.errors.VerifyError will be raised if a call to decoy.Decoy.verify does not match the given rehearsal. This is a normal assertion, and means your code under test isn't behaving according to your test's specification.</p> <pre><code>func = decoy.mock()\n\nfunc(\"hello\")\n\ndecoy.verify(func(\"goodbye\"))  # raises a VerifyError\n</code></pre>"},{"location":"usage/errors-and-warnings/#missingrehearsalerror","title":"MissingRehearsalError","text":"<p>A decoy.errors.MissingRehearsalError will be raised if Decoy cannot pop a rehearsal call off its call stack during a call to decoy.Decoy.when or decoy.Decoy.verify. This is a runtime error and means your test is using Decoy incorrectly.</p> <pre><code>decoy.when().then_return(42)  # raises a MissingRehearsalError\n</code></pre> <p>If you're working with async/await code, this can also happen if you forget to include <code>await</code> in your rehearsal, because the <code>await</code> is necessary for the spy's call handler to add the call to the stack.</p> <pre><code>decoy.when(await some_async_func(\"hello\")).then_return(\"world\")  # all good\ndecoy.when(some_async_func(\"hello\")).then_return(\"world\")  # will raise\n</code></pre>"},{"location":"usage/errors-and-warnings/#mocknotasyncerror","title":"MockNotAsyncError","text":"<p>A decoy.errors.MockNotAsyncError will be raised if you pass an <code>async def</code> function to decoy.Stub.then_do of a non-synchronous mock.</p> <pre><code>async_mock = decoy.mock(name=\"async_mock\", is_async=True)\nasync_mock = decoy.mock(name=\"sync_mock\")\n\nasync def _handle_call(input: str) -&gt; str:\n    print(input)\n    return \"world\"\n\ndecoy.when(await async_mock(\"hello\")).then_do(_handle_call)  # all good\ndecoy.when(sync_mock(\"hello\")).then_do(_handle_call)  # will raise\n</code></pre>"},{"location":"usage/errors-and-warnings/#mocknamerequirederror","title":"MockNameRequiredError","text":"<p>A decoy.errors.MockNameRequiredError will be raised if you call decoy.Decoy.mock without <code>cls</code>, <code>func</code>, nor <code>name</code>.</p> <p>If you pass <code>cls</code> or <code>func</code>, Decoy will infer the mock's name - to be used in assertion messages - from its source specification. If you don't pass a specification, you must give the mock an explicit name using the <code>name</code> argument.</p> <pre><code>my_mock = decoy.mock(name=\"my_mock\")\n</code></pre>"},{"location":"usage/errors-and-warnings/#warnings","title":"Warnings","text":"<p>Decoy uses Python's warnings system to provide feedback about dubious mock usage that isn't technically incorrect. These warnings won't fail your tests, but you probably want to fix them.</p>"},{"location":"usage/errors-and-warnings/#decoywarning","title":"DecoyWarning","text":"<p>A decoy.warnings.DecoyWarning is the base class of all warnings raised by Decoy. This warning will never be raised directly, but can be used in warning filters.</p> <p>For example, you could set all Decoy warnings to errors or ignore them all entirely. Neither of these configurations are recommended; Decoy considers the default \"warning\" level to be correct.</p> <pre><code># ignore all Decoy warnings in a module (not recommended!)\npytestmark = pytest.mark.filterwarnings(\"ignore::decoy.warnings.DecoyWarning\")\n</code></pre>"},{"location":"usage/errors-and-warnings/#miscalledstubwarning","title":"MiscalledStubWarning","text":"<p>A decoy.warnings.MiscalledStubWarning is a warning provided mostly for productivity convenience. If you configure a stub but your code under test calls the stub incorrectly, it can sometimes be difficult to immediately figure out what went wrong. This warning exists to alert you if:</p> <ul> <li>A mock has at least 1 stubbing configured with decoy.Decoy.when</li> <li>A call was made to the mock that didn't match any configured stubbing</li> </ul> <p>In the example below, our test subject is supposed to call a <code>DataGetter</code> dependency and pass the output data into a <code>DataHandler</code> dependency to get the result. However, in writing <code>Subject.get_and_handle_data</code>, we forgot to pass <code>data_id</code> into <code>DataGetter.get</code>.</p> <pre><code># test_subject.py\n\nclass Subject:\n    def __init__(self, data_getter, data_handler):\n        self._data_getter = data_getter\n        self._data_handler = data_handler\n\n    def get_and_handle_data(self, data_id):\n        data = self._data_getter.get()  # &lt;-- oops!\n        result = self._data_handler.handle(data)\n        return result\n\ndef test_subject(decoy: Decoy):\n    data_getter = decoy.mock(cls=DataGetter)\n    data_handler = decoy.mock(cls=DataHandler)\n    subject = Subject(data_getter=data_getter, data_handler=data_handler)\n\n    decoy.when(data_getter.get(\"data-id\")).then_return(42)\n    decoy.when(data_handler.handle(42)).then_return(\"good job\")\n\n    result = subject.get_and_handle_data(\"data-id\")\n\n    assert result == \"good job\"\n</code></pre> <p>When run, <code>self._data_getter.get()</code> will no-op and return <code>None</code>, because no matching stub configuration was found. That <code>None</code> will be fed into <code>self._data_handler.handle</code>, which will also no-op and return <code>None</code>, for the same reason. The test output will then tell us:</p> <pre><code>E       AssertionError: assert None == 'good job'\n</code></pre> <p>The test failed, which is good! But, the developer's next steps to fix the error aren't immediately obvious.</p> <p>Your first reaction, especially if you're coming from a mocking library like unittest.mock, might be \"We need to add an assertion that <code>data_getter.get</code> was called correctly.\" This would be bad, though! See RedundantVerifyWarning below for why adding an assertion like this would be redundant and potentially harmful.</p> <p>Even if we shouldn't add an assertion, we still want something to help us find the underlying issue. This is where <code>MiscalledStubWarning</code> comes in. When this test is run, Decoy will print the following warnings:</p> <pre><code>tests/test_example.py::test_subject\n  /path/to/decoy/verifier.py:72: MiscalledStubWarning: Stub was called but no matching rehearsal found.\n  Found 1 rehearsal:\n  1.    DataGetter.get('data-id')\n  Found 1 call:\n  1.    DataGetter.get()\n    warn(MiscalledStubWarning(calls=unmatched, rehearsals=rehearsals))\n\ntests/test_example.py::test_subject\n  /path/to/decoy/verifier.py:72: MiscalledStubWarning: Stub was called but no matching rehearsal found.\n  Found 1 rehearsal:\n  1.    DataHandler.handle(42)\n  Found 1 call:\n  1.    DataHandler.handle(None)\n    warn(MiscalledStubWarning(calls=unmatched, rehearsals=rehearsals))\n</code></pre> <p>These warnings tell us that something probably went wrong with how the dependency was called, allowing us to fix the issue and move on.</p>"},{"location":"usage/errors-and-warnings/#redundantverifywarning","title":"RedundantVerifyWarning","text":"<p>A decoy.warnings.RedundantVerifyWarning is a warning provided to prevent you from writing redundant and over-constraining <code>verify</code> calls to mocks that have been configured with <code>when</code>.</p> <p>Coming from unittest.mock, you're probably used to this workflow for mocks that return data:</p> <ol> <li>Configure an unconditional return value or side effect</li> <li>Call your test subject</li> <li>Assert that mock was called correctly</li> </ol> <p>Decoy, however, believes that, for data provider dependencies, asserting that a mock was called correctly is an over-constraint of the system. Instead, you set up Decoy stubs with:</p> <ol> <li>Configure a return value or side effect if and only if it is given the correct input</li> <li>Call your test subject<ul> <li>Your test subject will only trigger the configured behavior if it calls the mock correctly</li> </ul> </li> </ol> <p>This, however, may require a shift in how you think about mocks in your tests. Until that shift happens, you may be tempted to write:</p> <pre><code>def test_subject(decoy: Decoy):\n    data_getter = decoy.mock(cls=DataGetter)\n    data_handler = decoy.mock(cls=DataHandler)\n    subject = Subject(data_getter=data_getter, data_handler=data_handler)\n\n    decoy.when(data_getter.get(\"data-id\")).then_return(42)\n    decoy.when(data_handler.handle(42)).then_return(\"good job\")\n\n    result = subject.get_and_handle_data(\"data-id\")\n\n    assert result == \"good job\"\n    decoy.verify(data_getter.get(\"data-id\"))  # redundant, but feels good\n    decoy.verify(data_getter.handler(42))     # redundant, but feels good\n</code></pre> <p>Adding those <code>verify</code>s at the end may give you a feeling of \"ok, good, now I'm completely testing the interaction,\" but that feeling is a fallacy. Thanks to the input specification in <code>when</code>, the test will already pass or fail correctly. At best, the <code>verify</code> calls do nothing, and at worst, they punish the test subject if it's able to accomplish its work in some other way, coupling our test to the subject's implementation unnecessarily.</p> <p>If Decoy detects a <code>verify</code> with the same configuration of a <code>when</code>, it will raise a <code>RedundantVerifyWarning</code> to encourage you to remove the redundant, over-constraining <code>verify</code> call.</p>"},{"location":"usage/errors-and-warnings/#incorrectcallwarning","title":"IncorrectCallWarning","text":"<p>If you provide a Decoy mock with a specification <code>cls</code> or <code>func</code>, any calls to that mock will be checked according to <code>inspect.signature</code>. If the call does not match the signature, Decoy will raise a decoy.warnings.IncorrectCallWarning.</p> <p>While Decoy will merely issue a warning, this call would likely cause the Python engine to error at runtime and should not be ignored. In the next major version of Decoy, this warning will become an error.</p> <pre><code>def some_func(val: string) -&gt; int:\n    ...\n\nspy = decoy.mock(func=some_func)\n\nspy(\"hello\")                # ok\nspy(val=\"world\")            # ok\nspy(wrong_name=\"ah!\")       # triggers an IncorrectCallWarning\nspy(\"too\", \"many\", \"args\")  # triggers an IncorrectCallWarning\n</code></pre>"},{"location":"usage/matchers/","title":"Comparing with matchers","text":"<p>Sometimes, when you're stubbing or verifying calls (or really when you're doing any sort of equality assertion in a test), you need to loosen a given assertion. For example, you may want to assert that a dependency is called with a string, but you don't care about the full contents of that string.</p> <p>Decoy includes the decoy.matchers module, which is a set of Python classes with <code>__eq__</code> methods defined that you can use in rehearsals and/or assertions in place of actual values</p>"},{"location":"usage/matchers/#available-matchers","title":"Available matchers","text":"Matcher Description decoy.matchers.Anything Matches any value that isn't <code>None</code> decoy.matchers.DictMatching Matches a <code>dict</code> based on some of its values decoy.matchers.ErrorMatching Matches an <code>Exception</code> based on its type and message decoy.matchers.HasAttributes Matches an object based on its attributes decoy.matchers.IsA Matches using <code>isinstance</code> decoy.matchers.IsNot Matches anything that isn't a given value decoy.matchers.StringMatching Matches a string against a regular expression decoy.matchers.Captor Captures the comparison value (see below)"},{"location":"usage/matchers/#basic-usage","title":"Basic usage","text":"<p>To use, import <code>decoy.matchers</code> and use a matcher wherever you would normally use a value.</p> <pre><code>import pytest\nfrom typing import cast, Optional\nfrom decoy import Decoy, matchers\n\nfrom .logger import Logger\nfrom .my_thing import MyThing\n\ndef test_log_warning(decoy: Decoy):\n    logger = decoy.mock(cls=Logger)\n\n    subject = MyThing(logger=logger)\n\n    # call code under test\n    subject.log_warning(\"Oh no, something went wrong with request abc123efg456\")\n\n    # verify double called correctly\n    decoy.verify(\n        logger.warn(matchers.StringMatching(\"request abc123efg456\"))\n    )\n</code></pre>"},{"location":"usage/matchers/#capturing-values","title":"Capturing values","text":"<p>When testing certain APIs, especially callback APIs, it can be helpful to capture the values of arguments passed to a given dependency. For this, Decoy provides decoy.matchers.Captor.</p> <p>For example, our test subject may register an event listener handler, and we want to test our subject's behavior when the event listener is triggered.</p> <pre><code>import pytest\nfrom typing import cast, Optional\nfrom decoy import Decoy, matchers\n\nfrom .event_source import EventSource\nfrom .event_consumer import EventConsumer\n\n\ndef test_event_listener(decoy: Decoy):\n    event_source = decoy.mock(cls=EventSource)\n    subject = EventConsumer(event_source=event_source)\n    captor = matchers.Captor()\n\n    # subject registers its listener when started\n    subject.start_consuming()\n\n    # verify listener attached and capture the listener\n    decoy.verify(event_source.register(event_listener=captor))\n\n    # trigger the listener\n    event_handler = captor.value  # or, equivalently, captor.values[0]\n\n    assert subject.has_heard_event is False\n    event_handler()\n    assert subject.has_heard_event is True\n</code></pre> <p>This is a pretty verbose way of writing a test, so in general, you may want to approach using <code>matchers.Captor</code> as a form of potential code smell / test pain. There are often better ways to structure your code for these sorts of interactions that don't involve private functions.</p> <p>For further reading on when (or rather, when not) to use argument captors, check out testdouble's documentation on its argument captor matcher.</p>"},{"location":"usage/matchers/#writing-custom-matchers","title":"Writing custom matchers","text":"<p>You can write your own matcher class and use it wherever you would use a built-in matcher. All you need to do is define a class with an <code>__eq__</code> method:</p> <pre><code>class Is42:\n    def __eq__(self, other: object) -&gt; bool:\n        return other == 42\n\ncheck_answer = decoy.mock(name=\"check_answer\")\n\ndecoy.when(\n    check_answer(Is42())\n).then_return(\"huzzah!\")\n\nassert check_answer(42) == \"huzzah!\"\nassert check_answer(43) is None\n</code></pre> <p>This is especially useful if the value objects you are using as arguments are difficult to compare and out of your control. For example, Pandas DataFrame objects do not return a <code>bool</code> from <code>__eq__</code>, which makes it difficult to compare calls.</p> <p>We can define a <code>MatchesDataFrame</code> class to work around this:</p> <pre><code>import pandas as pd\n\nclass MatchesDataFrame:\n    def __init__(self, data) -&gt; None:\n        self._data_frame = pd.DataFrame(data)\n\n    def __eq__(self, other: object) -&gt; bool:\n        return self._data_frame.equals(other)\n\ncheck_data = decoy.mock(name=\"check_data\")\n\ndecoy.when(\n    check_answer(MatchesDataFrame({\"x1\": range(1, 42)}))\n).then_return(\"huzzah!\")\n\nassert check_data(pd.DataFrame({\"x1\": range(1, 42)})) == \"huzzah!\"\nassert check_data(pd.DataFrame({\"x1\": range(1, 43)})) is None\n</code></pre>"},{"location":"usage/verify/","title":"Spying with verify","text":"<p>A spy is an object that simply records all calls made to it. Use decoy.Decoy.verify to make assertions about calls to a spy, after those calls have been made. Asserting that calls happened after the fact is useful for dependencies called solely for their side-effects.</p> <p>In general, functions that produce side-effects instead of returning data are harder to test, typecheck, and maintain. To use Decoy to minimize side effects and increase the maintainability of your code, prefer writing tests - and therefore, your dependencies' APIs - to use stubbing with when rather than call verification with <code>verify</code>.</p> <p>Tip</p> <p>If a mocked dependency returns data that is used by your test subject, you should use when, not <code>verify</code>. Prefer using <code>when</code> over <code>verify</code> to guide the structure of your code to minimize side-effects.</p> <p>Usage of <code>when</code> and <code>verify</code> with the same mock are mutually exclusive within a test, and will trigger a warning. See the RedundantVerifyWarning guide for more information.</p>"},{"location":"usage/verify/#verifying-a-call","title":"Verifying a call","text":"<p>The <code>verify</code> API uses the same \"rehearsal\" syntax as when.</p> <ol> <li>Form the expected call to the mock</li> <li>Wrap it in <code>decoy.verify</code></li> </ol> <pre><code>database = decoy.mock(name=\"database\")\n\ndatabase.remove(\"some-id\")  # &lt;-- call to the spy\n\ndecoy.verify(\n    database.remove(\"some-id\"),  # &lt;-- verify the spy was called in this manner\n    times=1,\n)\n</code></pre> <p>By default, if Decoy finds any call matching the <code>verify</code> invocation, the call will pass. However, if a matching call is not found, a VerifyError will be raised.</p>"},{"location":"usage/verify/#verifying-a-call-count","title":"Verifying a call count","text":"<p>You can use the optional <code>times</code> argument to specify call count. With <code>times</code>, the call to <code>verify</code> will fail if there is the incorrect number of matching calls.</p> <p>Tip</p> <p>Prefer using the <code>times</code> argument, and only omit it if it really doesn't matter how many times a dependency is called by the test subject.</p> <pre><code>decoy.verify(\n    handler.should_be_called_once(),\n    times=1,\n)\n\ndecoy.verify(\n    handler.should_be_called_twice(),\n    times=2,\n)\n\ndecoy.verify(\n    handler.should_never_be_called(),\n    times=0,\n)\n</code></pre>"},{"location":"usage/verify/#loosening-constraints-with-matchers","title":"Loosening constraints with matchers","text":"<p>You may loosen rehearsal constraints using decoy.matchers. See the matchers usage guide for more information.</p> <pre><code>say_hello = decoy.mock(name=\"say_hello\")\n\nsay_hello(\"foobar\")\n\ndecoy.verify(matchers.StringMatching(\"^foo\"), times=1)  # passes\ndecoy.verify(matchers.StringMatching(\"^bar\"), times=1)  # raises\n</code></pre>"},{"location":"usage/verify/#verifying-with-asyncawait","title":"Verifying with async/await","text":"<p>If your dependency uses async/await, simply add <code>await</code> to the rehearsal:</p> <pre><code>cow_say = decoy.mock(name=\"cow_say\", is_async=True)\n\nawait cow_say(\"moo\")\n\ndecoy.verify(\n    await cow_say(\"moo\"),\n    times=1,\n)\n</code></pre> <p>If you create a mock based on a class or function using <code>mock(cls=...)</code> or <code>mock(func=...)</code>, Decoy will configure functions as <code>async</code> according to the source object.</p>"},{"location":"usage/verify/#verifying-order-of-multiple-calls","title":"Verifying order of multiple calls","text":"<p>If your code under test must call several dependencies in order, you may pass multiple rehearsals to <code>verify</code>. Decoy will search through the list of all calls made to the given spies and look for the exact rehearsal sequence given, in order.</p> <pre><code>decoy.verify(\n    handler.call_first_procedure(\"hello\"),\n    handler.call_second_procedure(\"world\"),\n)\n</code></pre>"},{"location":"usage/verify/#only-specify-some-arguments","title":"Only specify some arguments","text":"<p>If you don't care about some (or any) of the arguments passed to a spy, you can use the <code>ignore_extra_args</code> argument to tell Decoy to only check the arguments you pass.</p> <pre><code>def log(message: str, meta: Optional[dict] = None) -&gt; None:\n    ...\n\n# ...\nlog(\"hello world\", meta={\"foo\": \"bar\"})\n# ...\n\ndecoy.verify(\n    log(\"hello world\"),\n    ignore_extra_args=True,\n)\n</code></pre> <p>This can be combined with <code>times=0</code> to say \"this dependency was never called,\" but your typechecker may complain about this:</p> <pre><code># verify that something was never called in any way\ndecoy.verify(do_something(), times=0, ignore_extra_args=True)\n</code></pre>"},{"location":"usage/when/","title":"Stubbing with when","text":"<p>A stub is an object that is configured to return a result or raise an error if called according to a specification. Use decoy.Decoy.when to configure stubs.</p>"},{"location":"usage/when/#configuring-a-stub","title":"Configuring a stub","text":"<p>The <code>when</code> API uses a \"rehearsal\" syntax to configure a stub's conditions. To configure a stubbed behavior:</p> <ol> <li>Form the expected call to the mock</li> <li>Wrap it in <code>decoy.when</code></li> <li>Configure a behavior to trigger</li> </ol> <pre><code>database = decoy.mock(name=\"database\")\n\ndecoy.when(\n    database.get(\"some-id\")  # &lt;-- rehearsal\n).then_return(\n    {\"id\": \"some-id\"}   # &lt;-- behavior\n)\n\nassert database.get(\"some-id\") == {\"id\": \"some-id\"}\n</code></pre> <p>Any time your dependency is called in exactly the same way as the rehearsal, the latest configured behavior that matches that rehearsal will be triggered. Otherwise, it will return the default value of <code>None</code>.</p> <p>The \"rehearsal\" API gives us the following benefits:</p> <ul> <li>Your test double will only take action if it is called correctly<ul> <li>This avoids separate \"configure return\" and \"assert called\" steps</li> </ul> </li> <li>If you use type annotations, your rehearsal and behaviors can be type-checked<ul> <li>This helps prevent configuring your stubs incorrectly</li> </ul> </li> </ul>"},{"location":"usage/when/#returning-a-value","title":"Returning a value","text":"<p>To configure a return value, use decoy.Stub.then_return.</p> <pre><code>database = decoy.mock(name=\"database\")\n\ndecoy.when(\n    database.get(\"some-id\")  # &lt;-- when `database.get` is called with \"some-id\"\n).then_return(\n    {\"id\": \"some-id\"}  # &lt;-- then return the value `{\"id\": \"some-id\"}`\n)\n\nassert database.get(\"some-id\") == {\"id\": \"some-id\"}\n</code></pre> <p>The value that you pass to <code>then_return</code> can be checked by your type-checker.</p>"},{"location":"usage/when/#raising-an-error","title":"Raising an error","text":"<p>To configure a raised exception when called, use decoy.Stub.then_raise:</p> <pre><code>database = decoy.mock(name=\"database\")\n\ndecoy.when(\n    database.get(\"foo\")  # &lt;-- when `database.get` is called with \"foo\"\n).then_raise(\n    KeyError(\"foo does not exist\")  # &lt;-- then raise a KeyError\n)\n\nsubject.get_model_by_id(\"foo\")  # will raise KeyError\n</code></pre> <p>Note</p> <p>Configuring a stub to raise will make future rehearsals with the same arguments in the same test raise. If you must configure a new behavior after a raise in the same test, use a <code>try/except</code> block or <code>contextlib.suppress</code>. You should probably never do this, and instead use separate tests for different stub behaviors.</p> <pre><code>database = decoy.mock(name=\"database\")\n\ndecoy.when(database.get(\"foo\")).then_raise(KeyError(\"oh no\"))\n\n# ...later, in the same test\n\ndef _database_get(key):\n    with contextlib.suppress(KeyError):\n        database.get(key)\n\ndecoy.when(_database_get(\"foo\")).then_return(\"hurray!\")\n\nassert database.get(\"foo\") == \"hurray!\"\n</code></pre>"},{"location":"usage/when/#performing-an-action","title":"Performing an action","text":"<p>For complex situations, you may find that you want your stub to trigger a side-effect when called. For this, use decoy.Stub.then_do.</p> <p>This is a powerful feature, and if you find yourself reaching for it, you should first consider if your code under test can be reorganized to be tested in a more straightforward manner.</p> <pre><code>database = decoy.mock(name=\"database\")\n\ndef _side_effect(key):\n    print(f\"hello {key}\")\n    return {\"id\": key}\n\ndecoy.when(\n    database.get(\"foo\")  # &lt;-- when `database.get` is called with \"foo\"\n).then_do(\n    _side_effect  # &lt;-- then run `_side_effect` and return its result\n)\n\nassert database.get(\"foo\") == {id: \"foo\"}  # also prints \"hello foo\"\n</code></pre> <p>The action function passed to <code>then_do</code> will be passed any arguments given to the stub, and the stub will return whatever value is returned by the action.</p>"},{"location":"usage/when/#loosening-constraints-with-matchers","title":"Loosening constraints with matchers","text":"<p>You may loosen rehearsal constraints using decoy.matchers. See the matchers usage guide for more information.</p> <pre><code>say_hello = decoy.mock(name=\"say_hello\")\n\ndecoy.when(\n    say_hello(matchers.StringMatching(\"^foo\")\n).then_return(\n    \"hello\"\n)\n\nassert say_hello(\"foo\") == \"hello\"\nassert say_hello(\"foobar\") == \"hello\"\nassert say_hello(\"fizzbuzz\") is None\n</code></pre>"},{"location":"usage/when/#stubbing-with-asyncawait","title":"Stubbing with async/await","text":"<p>If your mock uses async/await, simply add <code>await</code> to the rehearsal:</p> <pre><code>compute_pi = decoy.mock(name=\"compute_pi\", is_async=True)\n\ndecoy.when(\n    await compute_pi()  # &lt;-- when compute_pi() is awaited\n).then_return(\n    3  # &lt;-- then return a value\n)\n\nassert await compute_pi() == 3\n</code></pre> <p>If you create a mock based on a class or function using <code>mock(cls=...)</code> or <code>mock(func=...)</code>, Decoy will configure functions as <code>async</code> according to the source object.</p> <p>When using <code>then_do</code> with an <code>async</code> mock, the callback may also be <code>async</code>.</p> <pre><code>compute_pi = decoy.mock(name=\"compute_pi\", is_async=True)\n\nasync def _side_effect():\n    print('close enough!')\n    return 3\n\ndecoy.when(await compute_pi()).then_do(_side_effect)\n\nassert await compute_pi() == 3  # also prints \"close enough!\"\n</code></pre>"},{"location":"usage/when/#only-specify-some-arguments","title":"Only specify some arguments","text":"<p>If you don't care about some (or any) of the arguments passed to a stub, you can use the <code>ignore_extra_args</code> argument to tell Decoy to only check the arguments you pass.</p> <pre><code>database = decoy.mock(cls=Database)\n\ndecoy.when(\n    database.get(\"some-id\"),\n    ignore_extra_args=True,\n).then_return(\n    {\"id\": \"some-id\"}\n)\n\n# database.get called with more args than specified\nresult = database.get(\"some-id\", hello=\"world\")\n\n# stubbed behavior still works\nassert result == {\"id\": \"some-id\"}\n</code></pre> <p>Note</p> <p>The <code>ignore_extra_args</code> option is best used with functions that use default parameter values. If your rehearsal does use all required parameters as specified by a mock's source object, you will trigger a decoy.warnings.IncorrectCallWarning.</p>"}]}